# Appendix

## What is AI and LLMs and How Do They Work?

### Core Concepts
* **Large Language Models (LLMs)**: Advanced AI systems trained on vast amounts of text data to understand and generate human-like text responses
* **Data Training**: The process of feeding large datasets to AI models to help them learn patterns, relationships, and generate appropriate outputs
* **RAG vs Finetune**: Comparison between Retrieval-Augmented Generation (adding context dynamically) and fine-tuning (specialized model training)
* **Agents / Agentic AI**: AI systems capable of taking autonomous actions based on objectives and context
* **Context Window**: The maximum amount of text an LLM can process in a single interaction, typically measured in tokens.  Think of this as the amount of information the LLM can hold in its memory.

### Technical Considerations
* **Temperature Setting**: Controls randomness in LLM outputs. Lower values (0) produce more deterministic responses, while higher values increase creativity
* **Context Management**: Strategies for working within LLM context window limitations
* **Environmental Impact**: Assessment of computational resources and energy consumption in AI operations

- something about using temperature of 0, context windows when calling llms

**Licensing** 
TODO - A note on Cursor and Windsurf Licences

**Privacy**
TODO - A note on Cursor and Windsurf Features

other stuff
- **Demonstrations**: Practical examples of AI implementation
* **Proof of Concepts**: Documented trials and experiments
* **Code Repositories**: Links to relevant Git repositories

